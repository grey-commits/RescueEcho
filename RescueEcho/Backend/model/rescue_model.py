# -*- coding: utf-8 -*-
"""RescueEcho.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i3gAZq0RfsDDHr5umBpihYpfcN0QZe_p
"""

from google.colab import drive
drive.mount('/content/drive')

zip_path = '/content/drive/MyDrive/Spectrograms.zip'

import zipfile
import os

# Extract ZIP file
zip_path = '/content/drive/MyDrive/Spectrograms.zip'
extract_path = '/content/Spectrograms'  # Extract to Colab's local storage

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Verify extraction
print(os.listdir(extract_path))

spectrograms_folder = '/content/Spectrograms/Spectrograms'
print(os.listdir(spectrograms_folder))

import tensorflow as tf

# Create a dataset from the extracted folder
dataset = tf.keras.utils.image_dataset_from_directory(
    spectrograms_folder,
    image_size=(128, 128),  # Resize as per your model's requirement
    batch_size=32
)

# View class names (if images are organized in subfolders by category)
print("Classes:", dataset.class_names)

import tensorflow as tf
base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(len(dataset.class_names), activation='softmax')
])

import tensorflow as tf

# Set the path to your dataset
dataset_dir = '/content/Spectrograms/Spectrograms'

# Load the dataset
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    dataset_dir,
    image_size=(224, 224),  # Adjust the image size as per your model's input requirements
    batch_size=32,  # Adjust batch size based on your GPU/CPU capacity
    label_mode='int',  # Use 'int' for integer labels or 'categorical' for one-hot encoded labels
    shuffle=True,  # Shuffle the data
    seed=42,  # Set a seed for reproducibility
)
base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False
model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    # Adjusted num_classes to match the dataset
    tf.keras.layers.Dense(13, activation='softmax')
])

val_size = int(0.2 * len(list(train_dataset)))  # 20% of the data for validation
train_dataset = train_dataset.skip(val_size)
val_dataset = train_dataset.take(val_size)


# Example of how to visualize the dataset
import matplotlib.pyplot as plt

# Get a batch of images
image_batch, label_batch = next(iter(train_dataset))

# Plot the first 4 images
plt.figure(figsize=(10, 10))
for i in range(4):
    ax = plt.subplot(2, 2, i + 1)
    plt.imshow(image_batch[i].numpy().astype("uint8"))
    plt.title(f"Label: {label_batch[i]}")
    plt.axis("off")
plt.show()

train_dataset = train_dataset.map(lambda x, y: (x / 255.0, y))
val_dataset = val_dataset.map(lambda x, y: (x / 255.0, y))

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal"),
    tf.keras.layers.RandomRotation(0.2),
    tf.keras.layers.RandomZoom(0.2),
])

train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))

model = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(128, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')  # Adjust number of classes accordingly
])

base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(3, activation='softmax')  # Adjust number of classes
])

import tensorflow as tf
import os

# Define dataset directory
dataset_dir = "Spectrograms/Spectrograms"  # Update this to your actual dataset path

# Step 1: Create Class Mapping
class_names = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])
class_mapping = {name: idx for idx, name in enumerate(class_names)}
print("Class mapping:", class_mapping)

# Step 2: Define Preprocessing Functions
def preprocess_image(file_path):
    # Read and decode image
    image = tf.io.read_file(file_path)
    image = tf.image.decode_png(image, channels=3)  # Change to decode_png or decode_jpeg based on your image format
    # Resize image to a fixed size
    image = tf.image.resize(image, [224, 224])
    # Normalize pixel values to [0, 1]
    image = tf.cast(image, tf.float32) / 255.0
    return image

def process_label(file_path):
    # Extract the class name from the file path
    parts = tf.strings.split(file_path, os.sep)
    class_name = parts[-2]
    class_id = class_mapping[class_name.numpy().decode('utf-8')]
    return tf.convert_to_tensor(class_id, dtype=tf.int64)

def load_data(file_path):
    # Process the label using tf.py_function
    label = tf.py_function(func=process_label, inp=[file_path], Tout=tf.int64)
    label = tf.reshape(label, [])  # Ensure label is scalar
    # Process the image
    image = preprocess_image(file_path)
    return image, label

# Step 3: Create Dataset
file_paths = tf.data.Dataset.list_files(f"{dataset_dir}/*/*", shuffle=True)
dataset = file_paths.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)

# Batch and prefetch for performance
batch_size = 32
dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)

# Split the dataset into train and validation sets
train_size = int(0.8 * sum(1 for _ in file_paths))  # 80% for training
train_dataset = dataset.take(train_size)
val_dataset = dataset.skip(train_size)

# Step 4: Verify Dataset
for images, labels in train_dataset.take(1):
    print("Image batch shape:", images.shape)
    print("Label batch shape:", labels.shape)

# Step 5: Build the Model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(class_mapping), activation='softmax')  # Output layer for all classes
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Step 6: Train the Model
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=10  # Adjust based on your requirements
)

import tensorflow as tf
import os

dataset_dir = "Spectrograms/Spectrograms"

class_names = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])
class_mapping = {name: idx for idx, name in enumerate(class_names)}
print("Class mapping:", class_mapping)

keys_tensor = tf.constant(list(class_mapping.keys()))
values_tensor = tf.constant(list(class_mapping.values()), dtype=tf.int64)
class_lookup_table = tf.lookup.StaticHashTable(
    initializer=tf.lookup.KeyValueTensorInitializer(keys_tensor, values_tensor),
    default_value=-1
)

def preprocess_image(file_path):
    image = tf.io.read_file(file_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, [224, 224])
    image = tf.cast(image, tf.float32) / 255.0
    return image

def process_label(file_path):
    parts = tf.strings.split(file_path, os.sep)
    class_name = parts[-2]
    class_id = class_lookup_table.lookup(class_name)
    class_id.set_shape([])
    return class_id

def load_data(file_path):
    label = process_label(file_path)
    image = preprocess_image(file_path)
    return image, label

file_paths = list(tf.io.gfile.glob(f"{dataset_dir}/*/*"))
dataset_size = len(file_paths)
file_paths_ds = tf.data.Dataset.from_tensor_slices(file_paths)

dataset = file_paths_ds.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)

def augment(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))
    return image, label

dataset = dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)

dataset = dataset.shuffle(buffer_size=dataset_size).cache().batch(32).prefetch(tf.data.AUTOTUNE)

train_size = int(0.8 * dataset_size)
train_dataset = dataset.take(train_size)
val_dataset = dataset.skip(train_size)

base_model = tf.keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights="imagenet"
)
base_model.trainable = False

model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(len(class_mapping), activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

callbacks = [
    tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True),
    tf.keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, verbose=1)
]

history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=20,
    callbacks=callbacks
)
model.save("RescueEcho_model.h5")
